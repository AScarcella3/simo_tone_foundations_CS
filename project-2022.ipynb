{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec6f05cf-3769-4381-b7eb-a9d8de052d69",
   "metadata": {},
   "source": [
    "You have to work on the [Dogs adoptions](https://drive.google.com/file/d/1wQsA0oB6wwYlnkvvcyBCmLk7QmgVWNax/view?usp=sharing) dataset. \n",
    "\n",
    "It contains three files:\n",
    "*  `dogs.csv`, shortly *dogs*\n",
    "*  `dogTravel.csv`, shortly *travels*\n",
    "*  `NST-EST2021-POP.csv`\n",
    "\n",
    "### Notes\n",
    "\n",
    "1.    It is mandatory to use GitHub for developing the project.\n",
    "1.    The project must be a jupyter notebook.\n",
    "1.    There is no restriction on the libraries that can be used, nor on the Python version.\n",
    "1.    All questions on the project **must** be asked in a public channel on [Zulip](https://focs.zulipchat.com).\n",
    "1.    At most 3 students can be in each group. You must create the groups by yourself.\n",
    "1.    You do not have to send me the project *before* the discussion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e6d8fb",
   "metadata": {},
   "source": [
    "### 0.1 Importing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e77cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Opening dogs.csv and checking columns\n",
    "with open(\"dogs.csv\", \"r\") as dogs_file:\n",
    "    headers = dogs_file.readline()\n",
    "    print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b20bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating 'dogs' df \n",
    "dogs = pd.read_csv(\"dogs.csv\", sep=',', doublequote='\"', low_memory=False)\n",
    "\n",
    "# Checking the head\n",
    "dogs.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4128c98c",
   "metadata": {},
   "source": [
    "### 0.2.1 Dogs df cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384c03fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For cleaning purpose, from this time on multiple dataframes are created\n",
    "# tmp_dog_full is the original dataframe. His shape is shown below.\n",
    "tmp_dog_full = pd.read_csv(\"dogs.csv\", sep=',', doublequote='\"', low_memory=False, encoding='utf-8')\n",
    "print(f'tmp_dog_full shape: {tmp_dog_full.shape}')\n",
    "\n",
    "# A new column called 'ok' is created, which is set to the opposite of whether the 'contact_state' column\n",
    "# contains numeric value or not. It checks which lines are ok and what needs to be managed in a different way, using contact_state as watermark\n",
    "tmp_dog_full['ok'] = ~tmp_dog_full.contact_state.str.isnumeric()\n",
    "\n",
    "# Makes all the column names lowercase and replaces dots with underscores in them\n",
    "tmp_dog_full.columns = [col.lower().replace(\".\", \"_\") for col in tmp_dog_full.columns]\n",
    "\n",
    "# A new dataframe, called tmp_dog_ok is created. It contains the rows\n",
    "# where 'ok' is True.\n",
    "tmp_dog_ok = tmp_dog_full[tmp_dog_full.ok == True]\n",
    "print('tmp_dog_ok:')\n",
    "display(tmp_dog_ok.head(5))\n",
    "\n",
    "# Checks that all rows are ok, and prints the number of unique contact_state.\n",
    "print('check all rows are ok')\n",
    "print(len(tmp_dog_ok.contact_state.unique()))\n",
    "tmp_dog_ok.contact_state.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42eb435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A new df, tmp_dog_not_ok, is created. It only contains the rows from the\n",
    "# original dataframe tmp_dog_full where the column 'ok' is False.\n",
    "# This is the complement of the dataframe tmp_dog_ok created previously.\n",
    "tmp_dog_not_ok = tmp_dog_full[tmp_dog_full.ok == False]\n",
    "print('tmp_dog_not_ok')\n",
    "display(tmp_dog_not_ok.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae361e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 100) #50\n",
    "\n",
    "# Managing \"not ok\" dataframe: split name column and shift the others\n",
    "# Let's see what the dataframe looks like before the cleaning.\n",
    "print('before')\n",
    "display(tmp_dog_not_ok.head(1))\n",
    "\n",
    "# tmp_dog_not_ok_fixed is created, with the same columns and indices as the original dataframe\n",
    "tmp_dog_not_ok_fixed = pd.DataFrame(columns=tmp_dog_not_ok.columns, index=tmp_dog_not_ok.index)\n",
    "\n",
    "# Copies the columns from 0 to 24 and from 26 to the end of the original datafame\n",
    "# to the new dataframe, but dropping the column 'accessed'.\n",
    "tmp_dog_not_ok_fixed.iloc[:, 0:24] =  tmp_dog_not_ok.iloc[:, 0:24].copy()\n",
    "tmp_dog_not_ok_fixed.iloc[:, 26:] =  tmp_dog_not_ok.iloc[:, 25:].drop('accessed', axis = 1).copy()\n",
    "\n",
    "# Taking the 24th column of the original dataframe and splitting it into\n",
    "# two new columns, 'name' and 'status'.\n",
    "tmp_dog_not_ok.iloc[: , 24]\n",
    "tmp_dog_not_ok_fixed.name = tmp_dog_not_ok.name.apply(lambda x : x.split('\\\",')[0])\n",
    "tmp_dog_not_ok_fixed.status = tmp_dog_not_ok.name.apply(lambda x : x.split('\\\",')[1].strip('\"'))\n",
    "print('after')\n",
    "tmp_dog_not_ok_fixed.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515963de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the two dataframes, 'tmp_dog_ok' and 'tmp_dog_not_ok_fixed' into 'dogs'.\n",
    "# It concatenates the two dataframes vertically.\n",
    "print('tmp_dog_ok shape:', tmp_dog_ok.shape)\n",
    "print('tmp_dog_not_ok shape:', tmp_dog_not_ok.shape)\n",
    "dogs = pd.concat([tmp_dog_ok, tmp_dog_not_ok_fixed])\n",
    "print('dogs shape:', dogs.shape)\n",
    "\n",
    "# Temporary dataframes are deleted.\n",
    "del tmp_dog_full\n",
    "del tmp_dog_not_ok\n",
    "del tmp_dog_not_ok_fixed\n",
    "del tmp_dog_ok\n",
    "\n",
    "# Makes all column names lowercase and replaces dots with underscores\n",
    "dogs.columns = [col.lower().replace(\".\", \"_\") for col in dogs.columns]\n",
    "\n",
    "# Dropping the 'ok' column\n",
    "dogs.drop('ok', axis=1, inplace=True)\n",
    "dogs.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "398c7554",
   "metadata": {},
   "source": [
    "### 0.2.2 Travels dataset cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439315fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The travels dataset is stored into the temporary 'tmp_travels' dataframe\n",
    "tmp_travels = pd.read_csv(\"dogTravel.csv\", sep=',', doublequote='\"', low_memory=False).drop('index', axis=1)\n",
    "\n",
    "# Data exploration\n",
    "display(tmp_travels.head())\n",
    "display(tmp_travels.contact_state.unique())\n",
    "display(tmp_travels[tmp_travels.contact_state == '17325'].id.unique())\n",
    "\n",
    "# The variable 'anomalies' is created, which contains the unique 'id' values\n",
    "# of the rows where the 'contact_state' is '17325'\n",
    "anomalies = tmp_travels[tmp_travels.contact_state == '17325'].id.unique()\n",
    "\n",
    "# Changing the 'contact_state' value of all the rows where the 'id' is equal \n",
    "# to the anomalies declared before.\n",
    "tmp_travels.loc[tmp_travels.id == anomalies[0], 'contact_state'] = 'PA'\n",
    "tmp_travels.loc[tmp_travels.id == anomalies[1], 'contact_state'] = 'PA'\n",
    "display(tmp_travels[tmp_travels.id.isin(anomalies)])\n",
    "display(tmp_travels.contact_state.unique())\n",
    "\n",
    "# Storing the tmp_travels with the fixed values into the original one, 'travels'\n",
    "travels = tmp_travels.copy()\n",
    "del tmp_travels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd2bd6ac",
   "metadata": {},
   "source": [
    "### 0.2.3 States df cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f871827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the states dataset into tmp_states\n",
    "tmp_states = pd.read_csv(\"NST-EST2021-POP.csv\", header=None, names=[\"state\", \"population\"], sep=',', low_memory=False)\n",
    "tmp_states.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aac638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing all occurrences of '.' in the 'population' column with an empty string\n",
    "tmp_states.population = tmp_states.population.str.replace('.', '', regex=False).astype(int)\n",
    "\n",
    "# Creating the original 'states' dataframe\n",
    "states = tmp_states.copy()\n",
    "del tmp_states\n",
    "states.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a0ffa6-ad32-446f-8780-eb3138658e14",
   "metadata": {},
   "source": [
    "### 1. Extract all dogs with status that is not *adoptable*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2de7a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10) #50\n",
    "\n",
    "print(dogs[dogs.status != 'adoptable'].shape)\n",
    "not_adoptable_dogs = dogs[dogs.status != 'adoptable']\n",
    "\n",
    "display(not_adoptable_dogs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d46848-9e88-4eae-96af-43263c16371e",
   "metadata": {},
   "source": [
    "### 2. For each (primary) breed, determine the number of dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcccf254",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs['breed_primary'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd288f44-e2f2-4420-b662-da98a666a8a9",
   "metadata": {},
   "source": [
    "### 3. For each (primary) breed, determine the ratio between the number of dogs of `Mixed Breed` and those not of Mixed Breed. Hint: look at the `secondary_breed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5186e6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the distinct breeds\n",
    "print('distinct breed: ', len(dogs.breed_primary.unique()))\n",
    "\n",
    "# Creating a new dataframe that groups the 'dogs' dataframe by the 'breed_primary' \n",
    "# column, counting the number of dogs for each breed and returning \n",
    "# the result sorted by the number of dogs\n",
    "breeds = dogs.groupby('breed_primary', as_index=False).count()[['breed_primary','id']].rename({'id': 'number_of_dogs'}, axis=1).sort_values(by='number_of_dogs', ascending=False)\n",
    "breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a170647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new dataframe sec_breeds that contains the count of mixed dogs \n",
    "# for each primary breed, by first filtering the 'dogs' dataframe to include only \n",
    "# the rows with not null values in the 'breed_secondary' column, then grouping \n",
    "# the filtered dataframe by 'breed_primary' and counting the number of dogs for each primary breed \n",
    "sec_breeds = dogs[dogs.breed_secondary.notnull()]\n",
    "sec_breeds = sec_breeds.groupby('breed_primary', as_index=False).count()[['breed_primary','id']].rename({'id': 'number_of_dogs'}, axis=1)\n",
    "sec_breeds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a3f68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging 'breeds' and 'sec_breeds' with a left-join into mix_breeds\n",
    "mix_breeds = breeds.merge(sec_breeds, on='breed_primary', how='left', suffixes=('_tot','_mixed'))\n",
    "mix_breeds['number_of_dogs_mixed'] = mix_breeds['number_of_dogs_mixed'].fillna(0)\n",
    "\n",
    "# Calculating the ratio\n",
    "mix_breeds['mixed_ratio_perc'] = mix_breeds.apply(lambda x : round(x.number_of_dogs_mixed/x.number_of_dogs_tot, 2)*100, axis=1)\n",
    "mix_breeds['pure_ratio_perc'] = mix_breeds.apply(lambda x : 100 - x.mixed_ratio_perc, axis=1)\n",
    "mix_breeds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94c4aed-9490-440d-af7e-744ed71e6819",
   "metadata": {},
   "source": [
    "### 4. For each (primary) breed, determine the earliest and the latest `posted` timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65173067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting the 'posted' column\n",
    "dogs['posted'] = pd.to_datetime(dogs['posted'], errors=\"coerce\")\n",
    "\n",
    "# Creating the df with earliest and latest 'posted' timestamps\n",
    "earliest_latest_timestamp = dogs.groupby('breed_primary', as_index=False).aggregate({'posted':[min, max]})\n",
    "\n",
    "earliest_latest_timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db828c77-9432-4533-9695-e45ec86dc885",
   "metadata": {},
   "source": [
    "### 5. For each state, compute the sex imbalance, that is the difference between male and female dogs. In which state this imbalance is largest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d55e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "malefemale = dogs[['contact_state', 'contact_city', 'contact_zip', 'contact_country', 'sex']].copy()\n",
    "\n",
    "# creating a new dataframe 'malefemale' and 'malefemale_imbalance' that shows the imbalance of male to female dogs by state\n",
    "malefemale['imbalance'] = malefemale.sex.apply(lambda x : 1 if x.upper() == 'MALE' else -1)\n",
    "malefemale_imbalance = malefemale.groupby('contact_state', as_index=False).sum('imbalance')[['contact_state', 'imbalance']]\n",
    "malefemale_imbalance.iloc[[malefemale_imbalance.imbalance.idxmin(), malefemale_imbalance.imbalance.idxmax()]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf98f50-14b1-4a48-9906-c71e614789c5",
   "metadata": {},
   "source": [
    "### 6. For each pair (age, size), determine the average duration of the stay and the average cost of stay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bc3b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the 'stay_duration' and 'stay_cost' to integer and float\n",
    "dogs.stay_duration = dogs.stay_duration.astype(int)\n",
    "dogs.stay_cost = dogs.stay_cost.astype(float)\n",
    "\n",
    "# Grouping the dogs by age and size, calculating the mean of the stay_duration and stay_cost\n",
    "stay = dogs.groupby(['age', 'size'], as_index=False).agg({'stay_duration' : 'mean', 'stay_cost' : 'mean'})\n",
    "\n",
    "# Rounding the values to 2 decimal places\n",
    "stay.stay_duration = stay.stay_duration.apply(lambda x : round(x, 2))\n",
    "stay.stay_cost = stay.stay_cost.apply(lambda x : round(x, 2))\n",
    "stay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b473c62b-ed47-41b4-9de9-38999c6c6427",
   "metadata": {},
   "source": [
    "### 7. Find the dogs involved in at least 3 travels. Also list the breed of those dogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04052aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the number of occurrences of each unique dog that traveled at least 3 times\n",
    "many_travels = travels[['id', 'contact_state']].groupby('id', as_index=False).count().rename({'contact_state':'travels'}, axis=1)\n",
    "many_travels = many_travels[many_travels.travels > 2]\n",
    "many_travels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b445bec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just a check\n",
    "travels[travels.id == 46042569]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4778a590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging many_travels and 'dogs' on the 'id' column\n",
    "breed_travels = many_travels.merge(dogs[['id', 'breed_primary']], left_on='id', right_on='id')\n",
    "\n",
    "# Sorting by the 'travels' column\n",
    "breed_travels.sort_values('travels', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af8db3f-9440-45f3-ab0a-7816a2f07eff",
   "metadata": {},
   "source": [
    "### 8. Fix the `travels` table so that the correct state is computed from  the `manual` and the `found` fields. If `manual` is not missing, then it overrides what is stored in `found`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2df598f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a copy\n",
    "exercise_8 = travels.copy()\n",
    "\n",
    "# If the value in the 'manual' column is null, then it assigns the value of the 'found' column of that \n",
    "# row, otherwise it assigns the value of the 'manual' column of that row.\n",
    "exercise_8.found = exercise_8.apply(lambda x : x['found'] if pd.isnull(x['manual']) else x['manual'] ,axis=1)\n",
    "exercise_8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b8ebc7-d50d-4718-9bfa-1a2f95679eba",
   "metadata": {},
   "source": [
    "### 9. For each state, compute the ratio between the number of travels and the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bcb330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charging a decoding table\n",
    "abbreviations = pd.read_csv(\"abbreviations.csv\", sep=',', quotechar='\"')\n",
    "print(abbreviations.shape)\n",
    "abbreviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226991a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking for anomalies before the merge\n",
    "anomalies = [s for s in states['state'].unique() if s not in abbreviations.state.unique()]\n",
    "print(f\"anomalies number in states df: {len(anomalies)}\")\n",
    "\n",
    "anomalies = [s for s in travels['contact_state'].unique() if s not in abbreviations.code.unique()]\n",
    "print(f\"anomalies number in travels df: {len(anomalies)}\")\n",
    "\n",
    "print('next state is missing in file of population: located in Canada')\n",
    "travels[travels['contact_state'].isin(anomalies)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b88ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the number of occurrences of each unique 'contact_state' value, returning the count of \n",
    "# travels grouped by contact_state\n",
    "travels_by_states = travels.groupby('contact_state', as_index=False).count()[['contact_state', 'id']].rename({'id' : 'travels', 'contact_state': 'code'}, axis=1)\n",
    "travels_by_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450fd001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matching state name to state code\n",
    "states_travels = states.merge(abbreviations[['state', 'code']], on='state')\n",
    "states_travels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2bd3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling missing values and computing the ratio\n",
    "states_travels = states_travels.merge(travels_by_states, on='code', how='left').fillna(0)\n",
    "states_travels['travels_per_people'] = states_travels.apply(lambda x : x['travels']/x['population'], axis=1)\n",
    "states_travels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac557be-0433-4c65-9e17-b10775e96d31",
   "metadata": {},
   "source": [
    "### 10. For each dog, compute the number of days from the `posted` day to the day of last access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eefdd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a df copy for this exercise\n",
    "exercise_10 = dogs[['id', 'name', 'posted', 'accessed']].copy()\n",
    "\n",
    "# Computing the number of days from the 'posted' day to the day of last access, assuming it's 'accessed' column\n",
    "# The value is stored in 'days_delay' column\n",
    "exercise_10['posted'] = pd.to_datetime(pd.to_datetime(exercise_10['posted']).dt.date)\n",
    "exercise_10['accessed'] = pd.to_datetime(exercise_10['accessed'])\n",
    "exercise_10['days_delay'] = (exercise_10['accessed'].dt.date - exercise_10['posted'].dt.date).dt.days\n",
    "\n",
    "# Printing the result\n",
    "exercise_10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f19f9e-ee36-4c50-a0d4-d36bd8135f7f",
   "metadata": {},
   "source": [
    "### 11. Partition the dogs according to the number of weeks from the `posted` day to the day of last access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752aeced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a df copy for this exercise\n",
    "exercise_11 = exercise_10\n",
    "\n",
    "# Creating a new column, 'weeks', that stores the number of weeks from the posted day to the day of last access\n",
    "exercise_11[\"weeks\"] = round(exercise_11[\"days_delay\"] // 7,0).astype(int)\n",
    "\n",
    "# Grouping the dogs in different partitions, based on 'weeks' value\n",
    "partitioned_dogs = exercise_11.groupby(\"weeks\").count()[['id']].rename({'id': 'number_of_dogs'}, axis=1)\n",
    "\n",
    "# Printing them\n",
    "partitioned_dogs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b476dbd5",
   "metadata": {},
   "source": [
    "### 12. Find for duplicates in the `dogs` dataset. Two records are duplicates if they have (1) same breeds and sex, and (2) they share at least 90% of the words in the description field. Extra points if you find and implement a more refined for determining if two rows are duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461b930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase, remove punctuation, tokenize, lemmatization\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop = stopwords.words('english')\n",
    "stop.extend(['dog', 'dogs', '-', 'old'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44762011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First step: remove dogs with no description\n",
    "descripted_dogs = dogs[dogs['description'].notnull()]\n",
    "print(f'{len(descripted_dogs)} have description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d988310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second step: find dog by equal 'breed_primary', 'sex', 'description'\n",
    "dupdog1= descripted_dogs[descripted_dogs[['breed_primary', 'sex', 'description']].duplicated(keep='first')][['id','breed_primary','sex', 'description']] \n",
    "dupdog2= descripted_dogs[descripted_dogs[['breed_primary', 'sex', 'description']].duplicated(keep='last')][['id','breed_primary','sex', 'description']]\n",
    "duplicated_dogs = pd.concat([dupdog1, dupdog2])\n",
    "duplicated_dogs = duplicated_dogs.drop_duplicates()\n",
    "duplicated_dogs_id = list(duplicated_dogs['id'])\n",
    "\n",
    "print(f'found {len(duplicated_dogs_id)} duplicated dogs on {descripted_dogs.shape[0]} dogs with description')\n",
    "\n",
    "duplicated_dogs.sort_values(by=['sex','breed_primary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a18378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third step: catching remaining duplicates\n",
    "print(f'{len(descripted_dogs)} - {len(duplicated_dogs)}' )\n",
    "\n",
    "# Removing duplicated records from descripted_dogs and then storing\n",
    "# the dataframe into dogs_12\n",
    "idx = descripted_dogs.index[descripted_dogs.isin(duplicated_dogs).any(1)]\n",
    "descripted_dogs = descripted_dogs.drop(idx)\n",
    "dogs_12 = descripted_dogs\n",
    "\n",
    "print(f'remain {len(dogs_12)} on {descripted_dogs.shape[0]} dogs')\n",
    "\n",
    "### SECOND OPTION ###\n",
    "# substraction_df = pd.merge(descripted_dogs, duplicated_dogs, how='outer', indicator='Duplicated')\n",
    "# dogs_12 = substraction_df[substraction_df[\"Duplicated\" == 'left_only']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c3e198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the dataframe to exclude NaN records from the 'description' column\n",
    "dogs_12['lemm_description'] = dogs_12.description.str.lower().str.replace('[^a-zA-Z0-9 \\w+\\.\\w+@\\w+\\.\\w \\w+@\\w+\\.\\w www.\\w+\\.\\w]',' ', regex=True)    \n",
    "dogs_12['lemm_description'] = dogs_12['lemm_description'].str.lower().str.replace('(\\w)(\\. )',r'\\1 ', regex=True).str.strip('.')  \n",
    "dogs_12['lemm_description'] = dogs_12['lemm_description'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split() if word not in stop])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c44203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "pd.set_option('display.max_colwidth', 500) #50\n",
    "\n",
    "# Creating the 'cleaned_description' column, applying several operations on the lemm_description column in dogs_12\n",
    "dogs_12['cleaned_description'] = dogs_12.lemm_description.str.replace('(\\w+)? ?(\\d+) (\\w+)',r'\\1\\2\\3', regex=True)\n",
    "dogs_12['cleaned_description'] = dogs_12.cleaned_description.str.replace(' \\w ',' ', regex=True)\n",
    "dogs_12['cleaned_description'] = dogs_12.cleaned_description.str.replace('\\s+',' ', regex=True)\n",
    "\n",
    "# Pruning the rows where 'cleaned_description' is null\n",
    "print(f'rows before pruning: {len(dogs_12)}')\n",
    "dogs_12 = dogs_12[dogs_12['cleaned_description'].notnull()]\n",
    "print(f'rows after pruning: {len(dogs_12)}')\n",
    "\n",
    "# Creating the description_counter and description_dictionary columns, with the frequency\n",
    "# of words and the keys of description_counter\n",
    "dogs_12['description_counter'] = dogs_12['cleaned_description'].apply(lambda x: dict(Counter(x.split()))) \n",
    "dogs_12['description_dictionary'] = dogs_12['description_counter'].apply(lambda x: sorted(set(x.keys()))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a4c156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating clusters by the 'breed_primary' and 'sex' columns, counting \n",
    "# the number of dogs in each group.\n",
    "print(f'dogs before clustering: {dogs_12.shape[0]}')\n",
    "dogs_clusters = dogs_12.groupby(['breed_primary', 'sex'])[['id']].count().reset_index().rename(columns={'id':'counts'})\n",
    "print(f'dogs after clustering: {dogs_clusters.counts.sum()}')\n",
    "print(f'dogs clusters: {dogs_clusters.shape}')\n",
    "dogs_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa035c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an empty list where the duplicates will be stored\n",
    "duplicated_couples = []\n",
    "counter = 0\n",
    "\n",
    "# Filtering one sex at a time to optimize calculations\n",
    "for sex in ['Male', 'Female']:\n",
    "    clusters_by_sex = dogs_clusters[dogs_clusters['sex'] == sex][['breed_primary','counts']]\n",
    "    dogs_by_sex = dogs_12[dogs_12['sex'] == sex]\n",
    "    cluster_size = clusters_by_sex.shape[0]\n",
    "    print(f'sex: {sex}')\n",
    "    cluster_number = 0\n",
    "    \n",
    "    # Analyzing one cluster at a time\n",
    "    for breed_primary, counts in clusters_by_sex.values:\n",
    "        \n",
    "        cluster_number = cluster_number + 1 \n",
    "        print(f'processing cluster number: {cluster_number} of {cluster_size}--> {breed_primary} ({counts})')\n",
    "        \n",
    "        \n",
    "        this_cluster = dogs_by_sex[dogs_by_sex['breed_primary']==breed_primary]\n",
    "        duplicated_id_already_found = []\n",
    "\n",
    "        # Comparing each record with the others in the cluster\n",
    "        for i in range(0, counts-1):\n",
    "\n",
    "            first_dog = this_cluster.iloc[i]\n",
    "            desc1 = first_dog['cleaned_description']\n",
    "            set1 = first_dog['description_dictionary']\n",
    "\n",
    "            # Starts another nested loop starting from the next dog and iterating over all the remaining dogs in the cluster\n",
    "            for j in range(i+1, counts):\n",
    "                counter = counter + 1\n",
    "                second_dog = this_cluster.iloc[j]\n",
    "                desc2 = second_dog['cleaned_description']\n",
    "                set2 = second_dog['description_dictionary']\n",
    "\n",
    "                # it calculates the overlap ratio by taking the length of the union of \n",
    "                # the 'description_dictionary' of the two dogs and dividing it by the length of their intersection.\n",
    "                union = len(set1 | set2)\n",
    "                intersect = len(set1 & set2)\n",
    "                overlap_ratio = intersect / union\n",
    "\n",
    "                duplicated_couples.append({'sex': sex, 'breed_primary':breed_primary, 'first':first_dog['id'], 'second':second_dog['id'], 'overlap_ratio':overlap_ratio})\n",
    "\n",
    "# Saving the duplicates to an external CSV for quick checks\n",
    "df = pd.DataFrame(duplicated_couples)\n",
    "df.to_csv(f'overlap_optimized.csv', index=False, sep=',', encoding='utf-8')  \n",
    "\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4d4716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the stopwerds percentage on all descriptions\n",
    "all_description_words = dogs_12.description.apply(lambda x : len(str(x).split())).sum()\n",
    "all_cleaned_words = dogs_12.cleaned_description.apply(lambda x : len(str(x).split())).sum()\n",
    "ratio_cleaned_words = all_cleaned_words/all_description_words\n",
    "\n",
    "print(f\"\"\"{ratio_cleaned_words}% of words are stopwords\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cef854",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'duplicates_full_optimized.csv', sep=',', encoding='utf-8')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016dafc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_threshold = 0.9\n",
    "estimate_threshold = starting_threshold * ratio_cleaned_words\n",
    "print(estimate_threshold)\n",
    "df['overlap_class'] = df.overlap_ratio.apply(lambda x: x if x == 1 else x//0.1/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1bfb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dup = df.copy()\n",
    "df_dup = df_dup[df_dup.overlap_class > estimate_threshold]\n",
    "df_dup.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34902d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_dup.shape)\n",
    "df_dup_single = pd.concat([df_dup.rename({'first':'id'}, axis=1)[['id','sex','breed_primary', 'overlap_class']] \n",
    "                              , df_dup.rename({'second':'id'}, axis=1)[['id','sex','breed_primary', 'overlap_class']]]).drop_duplicates()\n",
    "print(df_dup_single.shape)\n",
    "df_dup_single.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06006834",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dup_single.overlap_class.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef05bb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some random check for those first dog that have the same description\n",
    "print('it seems that most of descriptions that are identical, are ads')\n",
    "dogs[dogs.id.isin(duplicated_dogs[duplicated_dogs.description == duplicated_dogs.iloc[28].description]['id'])][['breed_primary','sex','name','description']].sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b891ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print result\n",
    "print(len(duplicated_dogs_id))\n",
    "duplicated_dogs_id.extend(list(df_dup_single['id'].values))\n",
    "print(len(set(duplicated_dogs_id)))\n",
    "result = dogs[dogs['id'].isin(set(duplicated_dogs_id))]\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
