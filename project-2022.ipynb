{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec6f05cf-3769-4381-b7eb-a9d8de052d69",
   "metadata": {},
   "source": [
    "You have to work on the [Dogs adoptions](https://drive.google.com/file/d/1wQsA0oB6wwYlnkvvcyBCmLk7QmgVWNax/view?usp=sharing) dataset. \n",
    "\n",
    "It contains three files:\n",
    "*  `dogs.csv`, shortly *dogs*\n",
    "*  `dogTravel.csv`, shortly *travels*\n",
    "*  `NST-EST2021-POP.csv`\n",
    "\n",
    "### Notes\n",
    "\n",
    "1.    It is mandatory to use GitHub for developing the project.\n",
    "1.    The project must be a jupyter notebook.\n",
    "1.    There is no restriction on the libraries that can be used, nor on the Python version.\n",
    "1.    All questions on the project **must** be asked in a public channel on [Zulip](https://focs.zulipchat.com).\n",
    "1.    At most 3 students can be in each group. You must create the groups by yourself.\n",
    "1.    You do not have to send me the project *before* the discussion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e6d8fb",
   "metadata": {},
   "source": [
    "### 0.1 Importing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e77cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Opening dogs.csv and checking columns\n",
    "with open(\"dogs.csv\", \"r\") as dogs_file:\n",
    "    headers = dogs_file.readline()\n",
    "    print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b20bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating 'dogs' df \n",
    "dogs = pd.read_csv(\"dogs.csv\", sep=',', doublequote='\"', low_memory=False)\n",
    "\n",
    "# Checking the head\n",
    "dogs.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4128c98c",
   "metadata": {},
   "source": [
    "### 0.2 Cleaning up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384c03fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dog_full = pd.read_csv(\"dogs.csv\", sep=',', doublequote='\"', low_memory=False, encoding='utf-8')\n",
    "print(f'tmp_dog_full shape: {tmp_dog_full.shape}')\n",
    "\n",
    "# check what lines are ok and what need to be managed in different way: use contact state as watermark\n",
    "tmp_dog_full['ok'] = ~tmp_dog_full.contact_state.str.isnumeric()\n",
    "tmp_dog_full.columns = [col.lower().replace(\".\", \"_\") for col in tmp_dog_full.columns]\n",
    "\n",
    "# split dataframe with different case\n",
    "tmp_dog_ok = tmp_dog_full[tmp_dog_full.ok == True]\n",
    "tmp_dog_not_ok = tmp_dog_full[tmp_dog_full.ok == False]\n",
    "print('tmp_dog_ok:')\n",
    "display(tmp_dog_ok.head(5))\n",
    "print('##################################')\n",
    "print('tmp_dog_not_ok')\n",
    "display(tmp_dog_not_ok.head(5))\n",
    "\n",
    "# check all rows are ok\n",
    "print(len(tmp_dog_ok.contact_state.unique()))\n",
    "tmp_dog_ok.contact_state.unique()\n",
    "\n",
    "# manage not ok dataframe: split name column and shift the others\n",
    "pd.set_option('display.max_colwidth', 100) #50\n",
    "print('before')\n",
    "display(tmp_dog_not_ok.head(1))\n",
    "tmp_dog_not_ok_fixed = pd.DataFrame(columns=tmp_dog_not_ok.columns, index=tmp_dog_not_ok.index)\n",
    "tmp_dog_not_ok_fixed.iloc[:, 0:24] =  tmp_dog_not_ok.iloc[:, 0:24].copy()\n",
    "tmp_dog_not_ok_fixed.iloc[:, 26:] =  tmp_dog_not_ok.iloc[:, 25:].drop('accessed', axis = 1).copy()\n",
    "tmp_dog_not_ok.iloc[: , 24]\n",
    "tmp_dog_not_ok_fixed.name = tmp_dog_not_ok.name.apply(lambda x : x.split('\\\",')[0])\n",
    "tmp_dog_not_ok_fixed.status = tmp_dog_not_ok.name.apply(lambda x : x.split('\\\",')[1].strip('\"'))\n",
    "print('after')\n",
    "tmp_dog_not_ok_fixed.head()\n",
    "\n",
    "# unify dataframes\n",
    "print('tmp_dog_ok shape:', tmp_dog_ok.shape)\n",
    "print('tmp_dog_not_ok shape:', tmp_dog_not_ok.shape)\n",
    "dogs = pd.concat([tmp_dog_ok, tmp_dog_not_ok_fixed])\n",
    "print('dogs shape:', dogs.shape)\n",
    "del tmp_dog_full\n",
    "del tmp_dog_not_ok\n",
    "del tmp_dog_not_ok_fixed\n",
    "del tmp_dog_ok\n",
    "\n",
    "dogs.columns = [col.lower().replace(\".\", \"_\") for col in dogs.columns]\n",
    "dogs.drop('ok', axis=1, inplace=True)\n",
    "dogs.columns\n",
    "\n",
    "\n",
    "# travels dataset\n",
    "\n",
    "tmp_travels = pd.read_csv(\"dogTravel.csv\", sep=',', doublequote='\"', low_memory=False).drop('index', axis=1)\n",
    "display(tmp_travels.head())\n",
    "display(tmp_travels.contact_state.unique())\n",
    "display(tmp_travels[tmp_travels.contact_state == '17325'].id.unique())\n",
    "anomalies = tmp_travels[tmp_travels.contact_state == '17325'].id.unique()\n",
    "tmp_travels.loc[tmp_travels.id == anomalies[0], 'contact_state'] = 'PA'\n",
    "tmp_travels.loc[tmp_travels.id == anomalies[1], 'contact_state'] = 'PA'\n",
    "display(tmp_travels[tmp_travels.id.isin(anomalies)])\n",
    "display(tmp_travels.contact_state.unique())\n",
    "\n",
    "travels = tmp_travels.copy()\n",
    "del tmp_travels\n",
    "\n",
    "# states dataset\n",
    "\n",
    "tmp_states = pd.read_csv(\"NST-EST2021-POP.csv\", header=None, names=[\"state\", \"population\"], sep=',', low_memory=False)\n",
    "tmp_states.head()\n",
    "\n",
    "tmp_states.population = tmp_states.population.str.replace('.', '', regex=False).astype(int)\n",
    "states = tmp_states.copy()\n",
    "del tmp_states\n",
    "states.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a0ffa6-ad32-446f-8780-eb3138658e14",
   "metadata": {},
   "source": [
    "### 1. Extract all dogs with status that is not *adoptable*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2de7a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dogs[dogs.status != 'adoptable'].shape)\n",
    "not_adoptable_dogs = dogs[dogs.status != 'adoptable']\n",
    "\n",
    "not_adoptable_dogs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d46848-9e88-4eae-96af-43263c16371e",
   "metadata": {},
   "source": [
    "### 2. For each (primary) breed, determine the number of dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcccf254",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs['breed_primary'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd288f44-e2f2-4420-b662-da98a666a8a9",
   "metadata": {},
   "source": [
    "### 3. For each (primary) breed, determine the ratio between the number of dogs of `Mixed Breed` and those not of Mixed Breed. Hint: look at the `secondary_breed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5186e6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('distinct breed: ', len(dogs.breed_primary.unique()))\n",
    "breeds = dogs.groupby('breed_primary', as_index=False).count()[['id', 'breed_primary']].sort_values(by='id', ascending=False)\n",
    "breeds\n",
    "\n",
    "## compute total mixed dogs by primary breed\n",
    "sec_breeds = dogs[dogs.breed_secondary.notnull()]\n",
    "sec_breeds = sec_breeds.groupby('breed_primary', as_index=False).count()[['breed_primary','id']]\n",
    "\n",
    "## compute ratios\n",
    "mix_breeds = breeds.merge(sec_breeds, on='breed_primary', how='left', suffixes=('_tot','_mixed'))\n",
    "mix_breeds.id_mixed = mix_breeds.id_mixed.fillna(0)\n",
    "mix_breeds['mixed_ratio'] = mix_breeds.apply(lambda x : round(x.id_mixed/x.id_tot, 2)*100, axis=1)\n",
    "mix_breeds['pure_ratio'] = mix_breeds.apply(lambda x : 100 - x.mixed_ratio, axis=1)\n",
    "mix_breeds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94c4aed-9490-440d-af7e-744ed71e6819",
   "metadata": {},
   "source": [
    "### 4. For each (primary) breed, determine the earliest and the latest `posted` timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65173067",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Formatting the 'posted' column\n",
    "dogs['posted'] = pd.to_datetime(dogs['posted'], errors=\"coerce\")\n",
    "\n",
    "## Creating the df with earliest and latest 'posted' timestamps\n",
    "earliest_latest_timestamp = dogs.groupby('breed_primary', as_index=False).aggregate({'posted':[min, max]})\n",
    "\n",
    "earliest_latest_timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db828c77-9432-4533-9695-e45ec86dc885",
   "metadata": {},
   "source": [
    "### 5. For each state, compute the sex imbalance, that is the difference between male and female dogs. In which state this imbalance is largest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d55e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "malefemale = dogs[['contact_state', 'contact_city', 'contact_zip', 'contact_country', 'sex']].copy()\n",
    "malefemale['imbalance'] = malefemale.sex.apply(lambda x : 1 if x.upper() == 'MALE' else -1)\n",
    "\n",
    "malefemale_imbalance = malefemale.groupby('contact_state', as_index=False).sum('imbalance')[['contact_state', 'imbalance']]\n",
    "malefemale_imbalance.iloc[[malefemale_imbalance.imbalance.idxmin(), malefemale_imbalance.imbalance.idxmax()]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf98f50-14b1-4a48-9906-c71e614789c5",
   "metadata": {},
   "source": [
    "### 6. For each pair (age, size), determine the average duration of the stay and the average cost of stay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bc3b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs.stay_duration = dogs.stay_duration.astype(int)\n",
    "dogs.stay_cost = dogs.stay_cost.astype(float)\n",
    "stay = dogs.groupby(['age', 'size'], as_index=False).agg({'stay_duration' : 'mean', 'stay_cost' : 'mean'})\n",
    "stay.stay_duration = stay.stay_duration.apply(lambda x : round(x, 2))\n",
    "stay.stay_cost = stay.stay_cost.apply(lambda x : round(x, 2))\n",
    "stay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b473c62b-ed47-41b4-9de9-38999c6c6427",
   "metadata": {},
   "source": [
    "### 7. Find the dogs involved in at least 3 travels. Also list the breed of those dogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04052aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO da capire se ho fatto bene a considerare contact_state o va usato found\n",
    "many_travels = travels[['id', 'contact_state']].groupby('id', as_index=False).count().rename({'contact_state':'travels'}, axis=1)\n",
    "many_travels = many_travels[many_travels.travels > 2]\n",
    "many_travels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4778a590",
   "metadata": {},
   "outputs": [],
   "source": [
    "more_travels = many_travels.merge(dogs[['id', 'breed_primary']], left_on='id', right_on='id')\n",
    "more_travels.sort_values('travels', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af8db3f-9440-45f3-ab0a-7816a2f07eff",
   "metadata": {},
   "source": [
    "### 8. Fix the `travels` table so that the correct state is computed from  the `manual` and the `found` fields. If `manual` is not missing, then it overrides what is stored in `found`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2df598f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a copy\n",
    "exercise_8 = travels.copy()\n",
    "\n",
    "exercise_8.found = exercise_8.apply(lambda x : x.found if pd.isnull(x['manual']) else x['manual'] ,axis=1)\n",
    "\n",
    "exercise_8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b8ebc7-d50d-4718-9bfa-1a2f95679eba",
   "metadata": {},
   "source": [
    "### 9. For each state, compute the ratio between the number of travels and the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1b6d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the NST-EST2021-POP.csv into a new df, 'populationsDf'\n",
    "populationsDf = pd.read_csv(\"NST-EST2021-POP.csv\", sep=',', doublequote='\"', low_memory=False, names=[\"found\", \"population\"])\n",
    "populationsDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17925d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "## TODO infatti se qua ti metti una left join....viene fuori... NARNIA :D \n",
    "## TODO invece NARNIA non esce perchè è una inner join, ma perdi 2000 record\n",
    "## TODO comunque prima di mettere in join exercise_8 bisogna farci su un group by per stato e contare i viaggi.\n",
    "## TODO inoltre questa mancata groupby è quella che ti fa uscire i duplicati qualche riga più su\n",
    "# Merge the two dataframes on the 'contact_state' column\n",
    "print(f'nomber of rows before merge: {exercise_8.shape[0]}')\n",
    "print(exercise_8.head(100))\n",
    "exercise_9 = exercise_8.merge(populationsDf, on='found')\n",
    "print(f'nomber of rows after merge: {exercise_9.shape[0]}')\n",
    "print(exercise_9['id'])\n",
    "\n",
    "# Removing duplicate rows based on the 'id' column, keeping the last occurrence of each duplicate row\n",
    "## TODO questi duplicati vengono fuori per il motivo che scrivo qualche riga più su\n",
    "exercise_9 = exercise_9.drop_duplicates(subset='id', keep='last')\n",
    "print(f'nomber of rows after drop: {exercise_9.shape[0]}')\n",
    "\n",
    "# Group the dataframe by the 'correct_state' column\n",
    "grouped_df = exercise_9.groupby('found')\n",
    "\n",
    "# Create an empty dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# Iterate through each group\n",
    "for name, group in grouped_df:\n",
    "    # Calculate the number of travels and the population\n",
    "    num_travels = group.shape[0]\n",
    "    population = group['population'].str.replace('.', '').astype(int).sum()\n",
    "    \n",
    "    # Calculate the ratio and store it in the dictionary\n",
    "    ratio = num_travels / population\n",
    "    results[name] = ratio\n",
    "\n",
    "# Convert the dictionary to a dataframe\n",
    "results_df = pd.DataFrame.from_dict(results, orient='index', columns=['ratio'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb5e52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(exercise_8.found.unique()))\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac557be-0433-4c65-9e17-b10775e96d31",
   "metadata": {},
   "source": [
    "### 10. For each dog, compute the number of days from the `posted` day to the day of last access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eefdd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a df copy for this exercise\n",
    "exercise_10 = dogs[['id', 'name', 'posted', 'accessed']].copy()\n",
    "\n",
    "# Computing the number of days from the 'posted' day to the day of last access, assuming it's 'accessed' column\n",
    "# The value is stored in 'days_delay' column\n",
    "exercise_10['posted'] = pd.to_datetime(pd.to_datetime(exercise_10['posted']).dt.date)\n",
    "exercise_10['accessed'] = pd.to_datetime(exercise_10['accessed'])\n",
    "exercise_10['days_delay'] = (exercise_10['accessed'].dt.date - exercise_10['posted'].dt.date).dt.days\n",
    "\n",
    "# Printing the result\n",
    "exercise_10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f19f9e-ee36-4c50-a0d4-d36bd8135f7f",
   "metadata": {},
   "source": [
    "### 11. Partition the dogs according to the number of weeks from the `posted` day to the day of last access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752aeced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a df copy for this exercise\n",
    "exercise_11 = exercise_10\n",
    "\n",
    "# Creating a new column, 'weeks', that stores the number of weeks from the posted day to the day of last access\n",
    "exercise_11[\"weeks\"] = round(exercise_11[\"days_delay\"] // 7,0).astype(int)\n",
    "\n",
    "# Grouping the dogs in different partitions, based on 'weeks' value\n",
    "partitioned_dogs = exercise_11.groupby(\"weeks\").count()[['id']].rename({'id': 'number_of_dogs'}, axis=1)\n",
    "# # Printing them\n",
    "partitioned_dogs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b476dbd5",
   "metadata": {},
   "source": [
    "### 12. Find for duplicates in the `dogs` dataset. Two records are duplicates if they have (1) same breeds and sex, and (2) they share at least 90% of the words in the description field. Extra points if you find and implement a more refined for determining if two rows are duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461b930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase, remove punctuation, tokenize, lemmatization\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop = stopwords.words('english')\n",
    "stop.extend(['dog', 'dogs', '-', 'old'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a18378",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_12 = dogs[['id', 'breed_primary', 'sex', 'description']].copy()\n",
    "# dogs_12['description'] = dogs_12['description'].fillna('-')\n",
    "\n",
    "# filtra il dataframe per escludere i record con valori NaN nella colonna 'description'\n",
    "dogs_12 = dogs_12[dogs_12['description'].notnull()]\n",
    "dogs_12['lemm_description'] = dogs_12.description.str.lower().str.replace('[^a-zA-Z0-9 \\w+\\.\\w+@\\w+\\.\\w \\w+@\\w+\\.\\w www.\\w+\\.\\w]',' ', regex=True)    \n",
    "dogs_12['lemm_description'] = dogs_12['lemm_description'].str.lower().str.replace('(\\w)(\\. )',r'\\1 ', regex=True).str.strip('.')  \n",
    "dogs_12['lemm_description'] = dogs_12['lemm_description'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split() if word not in stop])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c44203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "pd.set_option('display.max_colwidth', 500) #50\n",
    "\n",
    "dogs_12['cleaned_description'] = dogs_12.lemm_description.str.replace('(\\w+)? ?(\\d+) (\\w+)',r'\\1\\2\\3', regex=True)\n",
    "dogs_12['cleaned_description'] = dogs_12.cleaned_description.str.replace(' \\w ',' ', regex=True)\n",
    "dogs_12['cleaned_description'] = dogs_12.cleaned_description.str.replace('\\s+',' ', regex=True)\n",
    "print(f'rows before pruning: {len(dogs_12)}')\n",
    "dogs_12 = dogs_12[dogs_12['cleaned_description'].notnull()]\n",
    "print(f'rows after pruning: {len(dogs_12)}')\n",
    "dogs_12['description_counter'] = dogs_12['cleaned_description'].apply(lambda x: dict(Counter(x.split()))) \n",
    "dogs_12['description_dictionary'] = dogs_12['description_counter'].apply(lambda x: set(x.keys())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4d4716",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcolo la percentuale di stopwords sull'intero corpus di descrizioni\n",
    "all_description_words = dogs_12.description.apply(lambda x : len(str(x).split())).sum()\n",
    "all_cleaned_words = dogs_12.cleaned_description.apply(lambda x : len(str(x).split())).sum()\n",
    "ratio_cleaned_words = round(100*all_cleaned_words/all_description_words,2)\n",
    "\n",
    "print(f\"\"\"{ratio_cleaned_words}% of words are stopwords\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a4c156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusters = dogs_12[['breed_primary', 'sex']].drop_duplicates().shape\n",
    "# print(f'number of cluster: {clusters}')\n",
    "print(f'dogs before clustering: {dogs_12.shape[0]}')\n",
    "dogs_clusters = dogs_12.groupby(['breed_primary', 'sex'])[['id']].count().reset_index().rename(columns={'id':'counts'})\n",
    "print(f'dogs after clustering: {dogs_clusters.counts.sum()}')\n",
    "print(f'dogs clusters: {dogs_clusters.shape}')\n",
    "dogs_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa035c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crea una lista vuota per i duplicati\n",
    "duplicates = []\n",
    "threashold = 0.9\n",
    "counter = 0\n",
    "\n",
    "# filtro un sesso per volta per ottimizzare i calcoli\n",
    "for sex in ['Male', 'Female']:\n",
    "    clusters_by_sex = dogs_clusters[dogs_clusters['sex'] == sex][['breed_primary','counts']]\n",
    "    dogs_by_sex = dogs_12[dogs_12['sex'] == sex]\n",
    "    cluster_size = clusters_by_sex.shape[0]\n",
    "    print(f'sex: {sex}')\n",
    "    cluster_number = 0\n",
    "    \n",
    "    # analizzo un cluster per volta\n",
    "    for breed_primary, counts in clusters_by_sex.values:\n",
    "        \n",
    "        cluster_number = cluster_number + 1 \n",
    "        print(f'processing cluster number: {cluster_number} of {cluster_size}--> {breed_primary} ({counts})')\n",
    "        \n",
    "        \n",
    "        this_cluster = dogs_by_sex[dogs_by_sex['breed_primary']==breed_primary]       \n",
    "        # confronta ogni record con quelli successivi nel cluster\n",
    "        for i in range(0, counts-1):\n",
    "            first_dog = this_cluster.iloc[i]\n",
    "            desc1 = first_dog['cleaned_description']\n",
    "            set1 = first_dog['description_dictionary']\n",
    "            \n",
    "            for j in range(i+1, counts):\n",
    "                counter = counter + 1\n",
    "                second_dog = this_cluster.iloc[j]\n",
    "                desc2 = second_dog['cleaned_description']\n",
    "                set2 = second_dog['description_dictionary']\n",
    "               \n",
    "                if desc1 == desc2:\n",
    "                    duplicates.append({'sex': sex, 'breed_primary':breed_primary, 'first':first_dog['id'], 'second':second_dog['id'], 'overlap_ratio':1})\n",
    "                else:\n",
    "                # ...confronta le colonne 'cleaned_description'\n",
    "                    union = len(set1 | set2)\n",
    "                    intersect = len(set1 & set2)\n",
    "                    overlap_ratio = intersect / union\n",
    "                    duplicates.append({'sex': sex, 'breed_primary':breed_primary, 'first':first_dog['id'], 'second':second_dog['id'], 'overlap_ratio':1})\n",
    "             \n",
    "# salva i duplicati\n",
    "df = pd.DataFrame(duplicates)\n",
    "df.to_csv(f'clusters/duplicates_full.csv', index=False, sep=',', encoding='utf-8')  \n",
    "print(counter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
