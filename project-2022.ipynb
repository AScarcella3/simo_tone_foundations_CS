{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec6f05cf-3769-4381-b7eb-a9d8de052d69",
   "metadata": {},
   "source": [
    "You have to work on the [Dogs adoptions](https://drive.google.com/file/d/1wQsA0oB6wwYlnkvvcyBCmLk7QmgVWNax/view?usp=sharing) dataset. \n",
    "\n",
    "It contains three files:\n",
    "*  `dogs.csv`, shortly *dogs*\n",
    "*  `dogTravel.csv`, shortly *travels*\n",
    "*  `NST-EST2021-POP.csv`\n",
    "\n",
    "### Notes\n",
    "\n",
    "1.    It is mandatory to use GitHub for developing the project.\n",
    "1.    The project must be a jupyter notebook.\n",
    "1.    There is no restriction on the libraries that can be used, nor on the Python version.\n",
    "1.    All questions on the project **must** be asked in a public channel on [Zulip](https://focs.zulipchat.com).\n",
    "1.    At most 3 students can be in each group. You must create the groups by yourself.\n",
    "1.    You do not have to send me the project *before* the discussion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e6d8fb",
   "metadata": {},
   "source": [
    "### 0.1 Importing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e77cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Opening dogs.csv and checking columns\n",
    "with open(\"dogs.csv\", \"r\") as dogs_file:\n",
    "    headers = dogs_file.readline()\n",
    "    print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b20bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating 'dogs' df \n",
    "dogs = pd.read_csv(\"dogs.csv\", sep=',', doublequote='\"', low_memory=False)\n",
    "\n",
    "# Checking the head\n",
    "dogs.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4128c98c",
   "metadata": {},
   "source": [
    "### 0.2 Cleaning up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384c03fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dog_full = pd.read_csv(\"dogs.csv\", sep=',', doublequote='\"', low_memory=False, encoding='utf-8')\n",
    "print(f'tmp_dog_full shape: {tmp_dog_full.shape}')\n",
    "\n",
    "# check what lines are ok and what need to be managed in different way: use contact state as watermark\n",
    "tmp_dog_full['ok'] = ~tmp_dog_full.contact_state.str.isnumeric()\n",
    "tmp_dog_full.columns = [col.lower().replace(\".\", \"_\") for col in tmp_dog_full.columns]\n",
    "\n",
    "# split dataframe with different case\n",
    "tmp_dog_ok = tmp_dog_full[tmp_dog_full.ok == True]\n",
    "tmp_dog_not_ok = tmp_dog_full[tmp_dog_full.ok == False]\n",
    "print('tmp_dog_ok:')\n",
    "display(tmp_dog_ok.head(5))\n",
    "print('##################################')\n",
    "print('tmp_dog_not_ok')\n",
    "display(tmp_dog_not_ok.head(5))\n",
    "\n",
    "# check all rows are ok\n",
    "print(len(tmp_dog_ok.contact_state.unique()))\n",
    "tmp_dog_ok.contact_state.unique()\n",
    "\n",
    "# manage not ok dataframe: split name column and shift the others\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100) #50\n",
    "print('before')\n",
    "display(tmp_dog_not_ok.head(1))\n",
    "tmp_dog_not_ok_fixed = pd.DataFrame(columns=tmp_dog_not_ok.columns, index=tmp_dog_not_ok.index)\n",
    "tmp_dog_not_ok_fixed.iloc[:, 0:24] =  tmp_dog_not_ok.iloc[:, 0:24].copy()\n",
    "tmp_dog_not_ok_fixed.iloc[:, 26:] =  tmp_dog_not_ok.iloc[:, 25:].drop('accessed', axis = 1).copy()\n",
    "tmp_dog_not_ok.iloc[: , 24]\n",
    "tmp_dog_not_ok_fixed.name = tmp_dog_not_ok.name.apply(lambda x : x.split('\\\",')[0])\n",
    "tmp_dog_not_ok_fixed.status = tmp_dog_not_ok.name.apply(lambda x : x.split('\\\",')[1].strip('\"'))\n",
    "print('after')\n",
    "tmp_dog_not_ok_fixed.head()\n",
    "\n",
    "# unify dataframes\n",
    "print('tmp_dog_ok shape:', tmp_dog_ok.shape)\n",
    "print('tmp_dog_not_ok shape:', tmp_dog_not_ok.shape)\n",
    "dogs = pd.concat([tmp_dog_ok, tmp_dog_not_ok_fixed])\n",
    "print('dogs shape:', dogs.shape)\n",
    "del tmp_dog_full\n",
    "del tmp_dog_not_ok\n",
    "del tmp_dog_not_ok_fixed\n",
    "del tmp_dog_ok\n",
    "\n",
    "dogs.columns = [col.lower().replace(\".\", \"_\") for col in dogs.columns]\n",
    "dogs.drop('ok', axis=1, inplace=True)\n",
    "dogs.columns\n",
    "\n",
    "\n",
    "# travels dataset\n",
    "\n",
    "tmp_travels = pd.read_csv(\"dogTravel.csv\", sep=',', doublequote='\"', low_memory=False).drop('index', axis=1)\n",
    "display(tmp_travels.head())\n",
    "display(tmp_travels.contact_state.unique())\n",
    "display(tmp_travels[tmp_travels.contact_state == '17325'].id.unique())\n",
    "anomalies = tmp_travels[tmp_travels.contact_state == '17325'].id.unique()\n",
    "tmp_travels.loc[tmp_travels.id == anomalies[0], 'contact_state'] = 'PA'\n",
    "tmp_travels.loc[tmp_travels.id == anomalies[1], 'contact_state'] = 'PA'\n",
    "display(tmp_travels[tmp_travels.id.isin(anomalies)])\n",
    "display(tmp_travels.contact_state.unique())\n",
    "\n",
    "travels = tmp_travels.copy()\n",
    "del tmp_travels\n",
    "\n",
    "# states dataset\n",
    "\n",
    "tmp_states = pd.read_csv(\"NST-EST2021-POP.csv\", header=None, names=[\"state\", \"population\"], sep=',', low_memory=False)\n",
    "tmp_states.head()\n",
    "\n",
    "tmp_states.population = tmp_states.population.str.replace('.', '', regex=False).astype(int)\n",
    "states = tmp_states.copy()\n",
    "del tmp_states\n",
    "states.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a0ffa6-ad32-446f-8780-eb3138658e14",
   "metadata": {},
   "source": [
    "### 1. Extract all dogs with status that is not *adoptable*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2de7a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dogs[dogs.status != 'adoptable'].shape)\n",
    "not_adoptable_dogs = dogs[dogs.status != 'adoptable']\n",
    "\n",
    "not_adoptable_dogs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d46848-9e88-4eae-96af-43263c16371e",
   "metadata": {},
   "source": [
    "### 2. For each (primary) breed, determine the number of dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcccf254",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs['breed_primary'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd288f44-e2f2-4420-b662-da98a666a8a9",
   "metadata": {},
   "source": [
    "### 3. For each (primary) breed, determine the ratio between the number of dogs of `Mixed Breed` and those not of Mixed Breed. Hint: look at the `secondary_breed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70225fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting each combination\n",
    "dogs.groupby(['breed_primary','breed_secondary']).size().reset_index().rename(columns={0:'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf998615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a groupby for Mixed Breeds\n",
    "dogs.groupby('breed_primary')['breed_secondary'].apply(lambda x: (x=='Mixed Breed').sum()).reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c6a2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a groupby for those who aren't Mixed Breeds\n",
    "dogs.groupby('breed_primary')['breed_secondary'].apply(lambda x: (x!='Mixed Breed').sum()).reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee79ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing them in two different df\n",
    "mixed_breed = dogs.groupby('breed_primary')['breed_secondary'].apply(lambda x: (x=='Mixed Breed').sum()).reset_index(name='mixed')\n",
    "not_mixed_breed = dogs.groupby('breed_primary')['breed_secondary'].apply(lambda x: (x!='Mixed Breed').sum()).reset_index(name='not_mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b156cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the two df into a single one\n",
    "ratio_mixed = mixed_breed.merge(not_mixed_breed, left_on='breed_primary', right_on='breed_primary')\n",
    "\n",
    "ratio_mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b9fa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the ratio in a different column\n",
    "ratio_mixed['ratio'] = ratio_mixed['mixed']/ratio_mixed['not_mixed']\n",
    "\n",
    "ratio_mixed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94c4aed-9490-440d-af7e-744ed71e6819",
   "metadata": {},
   "source": [
    "### 4. For each (primary) breed, determine the earliest and the latest `posted` timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65173067",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Formatting the 'posted' column\n",
    "dogs['posted'] = pd.to_datetime(dogs['posted'], errors=\"coerce\")\n",
    "\n",
    "## Creating the df with earliest and latest 'posted' timestamps\n",
    "earliest_latest_timestamp = dogs.groupby('breed_primary', as_index=False).aggregate({'posted':[min, max]})\n",
    "\n",
    "earliest_latest_timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db828c77-9432-4533-9695-e45ec86dc885",
   "metadata": {},
   "source": [
    "### 5. For each state, compute the sex imbalance, that is the difference between male and female dogs. In which state this imbalance is largest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d55e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "malefemale = dogs[['contact_state', 'contact_city', 'contact_zip', 'contact_country', 'sex']].copy()\n",
    "malefemale['imbalance'] = malefemale.sex.apply(lambda x : 1 if x.upper() == 'MALE' else -1)\n",
    "\n",
    "malefemale_imbalance = malefemale.groupby('contact_state', as_index=False).sum('imbalance')[['contact_state', 'imbalance']]\n",
    "malefemale_imbalance.iloc[[malefemale_imbalance.imbalance.idxmin(), malefemale_imbalance.imbalance.idxmax()]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf98f50-14b1-4a48-9906-c71e614789c5",
   "metadata": {},
   "source": [
    "### 6. For each pair (age, size), determine the average duration of the stay and the average cost of stay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bc3b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs.stay_duration = dogs.stay_duration.astype(int)\n",
    "dogs.stay_cost = dogs.stay_cost.astype(float)\n",
    "stay = dogs.groupby(['age', 'size'], as_index=False).agg({'stay_duration' : 'mean', 'stay_cost' : 'mean'})\n",
    "stay.stay_duration = stay.stay_duration.apply(lambda x : round(x, 2))\n",
    "stay.stay_cost = stay.stay_cost.apply(lambda x : round(x, 2))\n",
    "stay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b473c62b-ed47-41b4-9de9-38999c6c6427",
   "metadata": {},
   "source": [
    "### 7. Find the dogs involved in at least 3 travels. Also list the breed of those dogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04052aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO da capire se ho fatto bene a considerare contact_state o va usato found\n",
    "many_travels = travels[['id', 'contact_state']].groupby('id', as_index=False).count().rename({'contact_state':'travels'}, axis=1)\n",
    "many_travels = many_travels[many_travels.travels > 2]\n",
    "many_travels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4778a590",
   "metadata": {},
   "outputs": [],
   "source": [
    "more_travels = many_travels.merge(dogs[['id', 'breed_primary']], left_on='id', right_on='id')\n",
    "more_travels.sort_values('travels', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af8db3f-9440-45f3-ab0a-7816a2f07eff",
   "metadata": {},
   "source": [
    "### 8. Fix the `travels` table so that the correct state is computed from  the `manual` and the `found` fields. If `manual` is not missing, then it overrides what is stored in `found`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2df598f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a copy\n",
    "exercise_8 = travels.copy()\n",
    "\n",
    "exercise_8.found = exercise_8.apply(lambda x : x.found if pd.isnull(x['manual']) else x['manual'] ,axis=1)\n",
    "\n",
    "exercise_8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b8ebc7-d50d-4718-9bfa-1a2f95679eba",
   "metadata": {},
   "source": [
    "### 9. For each state, compute the ratio between the number of travels and the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1b6d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the NST-EST2021-POP.csv into a new df, 'populationsDf'\n",
    "populationsDf = pd.read_csv(\"NST-EST2021-POP.csv\", sep=',', doublequote='\"', low_memory=False, names=[\"found\", \"population\"])\n",
    "populationsDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17925d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "## TODO infatti se qua ti metti una left join....viene fuori... NARNIA :D \n",
    "## TODO invece NARNIA non esce perchè è una inner join, ma perdi 2000 record\n",
    "## TODO comunque prima di mettere in join exercise_8 bisogna farci su un group by per stato e contare i viaggi.\n",
    "## TODO inoltre questa mancata groupby è quella che ti fa uscire i duplicati qualche riga più su\n",
    "# Merge the two dataframes on the 'contact_state' column\n",
    "print(f'nomber of rows before merge: {exercise_8.shape[0]}')\n",
    "print(exercise_8.head(100))\n",
    "exercise_9 = exercise_8.merge(populationsDf, on='found')\n",
    "print(f'nomber of rows after merge: {exercise_9.shape[0]}')\n",
    "print(exercise_9['id'])\n",
    "\n",
    "# Removing duplicate rows based on the 'id' column, keeping the last occurrence of each duplicate row\n",
    "## TODO questi duplicati vengono fuori per il motivo che scrivo qualche riga più su\n",
    "exercise_9 = exercise_9.drop_duplicates(subset='id', keep='last')\n",
    "print(f'nomber of rows after drop: {exercise_9.shape[0]}')\n",
    "\n",
    "# Group the dataframe by the 'correct_state' column\n",
    "grouped_df = exercise_9.groupby('found')\n",
    "\n",
    "# Create an empty dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# Iterate through each group\n",
    "for name, group in grouped_df:\n",
    "    # Calculate the number of travels and the population\n",
    "    num_travels = group.shape[0]\n",
    "    population = group['population'].str.replace('.', '').astype(int).sum()\n",
    "    \n",
    "    # Calculate the ratio and store it in the dictionary\n",
    "    ratio = num_travels / population\n",
    "    results[name] = ratio\n",
    "\n",
    "# Convert the dictionary to a dataframe\n",
    "results_df = pd.DataFrame.from_dict(results, orient='index', columns=['ratio'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb5e52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(exercise_8.found.unique()))\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac557be-0433-4c65-9e17-b10775e96d31",
   "metadata": {},
   "source": [
    "### 10. For each dog, compute the number of days from the `posted` day to the day of last access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eefdd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a df copy for this exercise\n",
    "exercise_10 = dogs[['id', 'name', 'posted', 'accessed']].copy()\n",
    "\n",
    "# Computing the number of days from the 'posted' day to the day of last access, assuming it's 'accessed' column\n",
    "# The value is stored in 'days_delay' column\n",
    "exercise_10['posted'] = pd.to_datetime(pd.to_datetime(exercise_10['posted']).dt.date)\n",
    "exercise_10['accessed'] = pd.to_datetime(exercise_10['accessed'])\n",
    "exercise_10['days_delay'] = (exercise_10['accessed'].dt.date - exercise_10['posted'].dt.date).dt.days\n",
    "\n",
    "# Printing the result\n",
    "exercise_10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f19f9e-ee36-4c50-a0d4-d36bd8135f7f",
   "metadata": {},
   "source": [
    "### 11. Partition the dogs according to the number of weeks from the `posted` day to the day of last access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752aeced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a df copy for this exercise\n",
    "exercise_11 = exercise_10\n",
    "\n",
    "# Creating a new column, 'weeks', that stores the number of weeks from the posted day to the day of last access\n",
    "exercise_11[\"weeks\"] = round(exercise_11[\"days_delay\"] // 7,0).astype(int)\n",
    "\n",
    "# Grouping the dogs in different partitions, based on 'weeks' value\n",
    "partitioned_dogs = exercise_11.groupby(\"weeks\").count()[['id']].rename({'id': 'number_of_dogs'}, axis=1)\n",
    "# # Printing them\n",
    "partitioned_dogs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b476dbd5",
   "metadata": {},
   "source": [
    "### 12. Find for duplicates in the `dogs` dataset. Two records are duplicates if they have (1) same breeds and sex, and (2) they share at least 90% of the words in the description field. Extra points if you find and implement a more refined for determining if two rows are duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b2ba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_12 = dogs[['id', 'breed_primary', 'sex', 'description']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461b930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase, remove punctuation, tokenize, lemmatization\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a18378",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop = stopwords.words('english')\n",
    "stop.extend(['dog', 'dogs', '-', 'old'])\n",
    "\n",
    "dogs_12['description'] = dogs_12['description'].fillna('-')\n",
    "\n",
    "dogs_12['lemm_description'] = dogs_12.description.str.lower().str.replace('[^a-zA-Z0-9 \\w+\\.\\w+@\\w+\\.\\w \\w+@\\w+\\.\\w www.\\w+\\.\\w]',' ', regex=True)    \n",
    "dogs_12['lemm_description'] = dogs_12['lemm_description'].str.lower().str.replace('(\\w)(\\. )',r'\\1 ', regex=True).str.strip('.')  \n",
    "dogs_12['lemm_description'] = dogs_12['lemm_description'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split() if word not in stop])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c44203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 500) #50\n",
    "\n",
    "dogs_12['replacing_description'] = dogs_12.lemm_description.str.replace('(\\w+)? ?(\\d+) (\\w+)',r'\\1\\2\\3', regex=True)\n",
    "dogs_12['replacing_description'] = dogs_12.replacing_description.str.replace(' \\w ',' ', regex=True)\n",
    "dogs_12['replacing_description'] = dogs_12.replacing_description.str.replace('\\s+',' ', regex=True)\n",
    "dogs_12.replacing_description.fillna('-',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27efc69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_12[dogs_12['id']==46039303][['replacing_description', 'lemm_description', 'description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d887d183",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter \n",
    "\n",
    "dogs_12['description_counter'] = dogs_12['replacing_description'].apply(lambda x: dict(Counter(x.split()))) \n",
    "dogs_12['description_dictionary'] = dogs_12['description_counter'].apply(lambda x: set(x.keys())) \n",
    "dogs_12[['id','replacing_description','lemm_description', 'description']]\n",
    "\n",
    "# filtra il dataframe per escludere i record con valori NaN nella colonna 'description'\n",
    "dogs_12 = dogs_12[dogs_12['replacing_description'].notnull()]\n",
    "dogs_12 = dogs_12[dogs_12['description'].notnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efccf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = set(dogs_12[dogs_12['id']==46042150]['description_counter'].values[0].keys())\n",
    "s2 = set(dogs_12[dogs_12['id']==45733027]['description_counter'].values[0].keys())\n",
    "print('-------')\n",
    "print(sorted(s1))\n",
    "print('-------')\n",
    "print(sorted(s2))\n",
    "print('-------')\n",
    "s = s1 & s2\n",
    "print(s)\n",
    "print(len(s))\n",
    "print('-------')\n",
    "S = s1.union(s2)\n",
    "print(S)\n",
    "print(len(S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e7b0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crea una lista vuota per i duplicati\n",
    "duplicates = []\n",
    "\n",
    "# seleziona casualmente un campione di 8000 record del dataframe\n",
    "dogs_12 = dogs_12.sample(8000)\n",
    "\n",
    "# itera su ogni record del dataframe\n",
    "for i, row in dogs_12.iterrows():\n",
    "    # confronta il record corrente con quelli successivi\n",
    "    for j in range(i + 1, len(dogs_12)):\n",
    "        # se 'breed_primary' e 'sex' sono uguali...\n",
    "        if row['breed_primary'] == dogs_12.iloc[j]['breed_primary'] and row['sex'] == dogs_12.iloc[j]['sex']:\n",
    "            # ...confronta le colonne 'description'\n",
    "            description1 = set(row['replacing_description'].split())\n",
    "            description2 = set(dogs_12.iloc[j]['replacing_description'].split())\n",
    "            union = len(description1 | description2)\n",
    "            if union > 0 and len(description1 & description2) / union >= 0.9:\n",
    "                # se i record condividono almeno il 90% delle parole, considerali duplicati\n",
    "                duplicates.append(row)\n",
    "\n",
    "# visualizza i duplicati\n",
    "print(duplicates)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59f24e67-8828-435d-9d91-56559f78cb10",
   "metadata": {},
   "source": [
    "### 12. [legacy] Find for duplicates in the `dogs` dataset. Two records are duplicates if they have (1) same breeds and sex, and (2) they share at least 90% of the words in the description field. Extra points if you find and implement a more refined for determining if two rows are duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5a2911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = dogs[['id', 'breed_primary', 'sex', 'description']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b59fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # seleziona casualmente un campione di 1000 record del dataframe\n",
    "# df = df.sample(8000)\n",
    "\n",
    "# # filtra il dataframe per escludere i record con valori NaN nella colonna 'description'\n",
    "# df = df[df['description'].notnull()]\n",
    "\n",
    "# # rimuovi i simboli dalla colonna 'description'\n",
    "# df['description'] = df['description'].str.replace(r'[^\\w\\s]', '')\n",
    "\n",
    "# # crea una lista vuota per i duplicati\n",
    "# duplicates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5aa5c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # itera su ogni record del dataframe\n",
    "# for i, row in df.iterrows():\n",
    "#     # confronta il record corrente con quelli successivi\n",
    "#     for j in range(i + 1, len(df)):\n",
    "#         # se 'breed_primary' e 'sex' sono uguali...\n",
    "#         if row['breed_primary'] == df.iloc[j]['breed_primary'] and row['sex'] == df.iloc[j]['sex']:\n",
    "#             # ...confronta le colonne 'description'\n",
    "#             description1 = set(row['description'].split())\n",
    "#             description2 = set(df.iloc[j]['description'].split())\n",
    "#             if len(description1 & description2) / len(description1 | description2) >= 0.9:\n",
    "#                 # se i record condividono almeno il 90% delle parole, considerali duplicati\n",
    "#                 duplicates.append(row)\n",
    "\n",
    "# # visualizza i duplicati\n",
    "# print(duplicates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "e135890deb9abdbf159e95a24fee8ceee79a42bd28c1baa764dc7174e1f564bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
